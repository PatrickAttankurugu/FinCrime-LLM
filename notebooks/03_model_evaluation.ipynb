{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["# Model Evaluation: FinCrime-LLM Performance Metrics\n\nComprehensive evaluation of the fine-tuned model using ROUGE, BLEU, and semantic similarity metrics."]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Import libraries\nimport torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom datasets import load_from_disk\nfrom evaluate import load\nimport numpy as np\nfrom tqdm import tqdm\n\nprint('✅ Libraries imported')"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 1. Load Model and Test Data"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Load fine-tuned model\nfrom inference.load_model import load_fincrime_model\n\nmodel_path = '../models/sar-mistral-7b/final'\nmodel, tokenizer = load_fincrime_model(model_path, load_in_4bit=True)\n\nprint(f'✅ Model loaded from {model_path}')"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Load test dataset\ndataset = load_from_disk('../data/processed/sar_dataset_alpaca')\ntest_data = dataset['test']\n\nprint(f'Test examples: {len(test_data)}')"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 2. Generate Predictions"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Generate predictions on test set\npredictions = []\nreferences = []\n\nfor example in tqdm(test_data.select(range(min(50, len(test_data)))), desc='Generating'):\n    prompt = f\"\"\"### Instruction:\\n{example['instruction']}\\n\\n### Input:\\n{example['input']}\\n\\n### Response:\\n\"\"\"\n    \n    inputs = tokenizer(prompt, return_tensors='pt', truncation=True).to(model.device)\n    \n    with torch.no_grad():\n        outputs = model.generate(**inputs, max_new_tokens=512, temperature=0.7)\n    \n    generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n    generated = generated.split('### Response:')[-1].strip()\n    \n    predictions.append(generated)\n    references.append(example['output'])\n\nprint(f'\\n✅ Generated {len(predictions)} predictions')"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 3. Calculate Metrics"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# ROUGE scores\nrouge = load('rouge')\nrouge_scores = rouge.compute(predictions=predictions, references=references)\n\nprint('\\nROUGE Scores:')\nfor key, value in rouge_scores.items():\n    print(f'  {key}: {value:.4f}')"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# BLEU scores\nbleu = load('bleu')\nbleu_score = bleu.compute(predictions=predictions, references=[[ref] for ref in references])\n\nprint(f'\\nBLEU Score: {bleu_score[\"bleu\"]:.4f}')"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 4. Qualitative Analysis"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["# Show example predictions\nimport random\n\nfor i in random.sample(range(len(predictions)), 3):\n    print('\\n' + '='*80)\n    print(f'Example {i+1}')\n    print('='*80)\n    print(f'\\nReference:\\n{references[i][:300]}...')\n    print(f'\\nPrediction:\\n{predictions[i][:300]}...')"]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ["## 5. Save Results"]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": ["import json\n\nresults = {\n    'rouge': rouge_scores,\n    'bleu': bleu_score,\n    'num_examples': len(predictions)\n}\n\nwith open('../evaluation_results.json', 'w') as f:\n    json.dump(results, f, indent=2)\n\nprint('✅ Results saved to evaluation_results.json')"]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
